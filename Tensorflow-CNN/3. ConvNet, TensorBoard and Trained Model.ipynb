{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd05bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D \n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "# Sequential model\n",
    "# Dense layer\n",
    "# Flatten is used before feeding to the final Dense\n",
    "# Importing TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66bcf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For utilising gpu for model processing\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb3fce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Cats-vs-dogs-cnn-64x2-{}\".format(int(time.time())) # Naming the model to identify in TensorBoard\n",
    "# Adding the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59816423",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs\\{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa769d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open(\"X.pickle\", \"rb\")) # Loading the data saved\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "X = X/255.0 # Normalize the data to scale of 0 to 1 max value=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8fb3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "22451/22451 [==============================] - 160s 7ms/sample - loss: 0.6100 - acc: 0.6552 - val_loss: 0.5750 - val_acc: 0.6894\n",
      "Epoch 2/10\n",
      "22451/22451 [==============================] - 168s 7ms/sample - loss: 0.5101 - acc: 0.7482 - val_loss: 0.4817 - val_acc: 0.7699\n",
      "Epoch 3/10\n",
      "22451/22451 [==============================] - 172s 8ms/sample - loss: 0.4681 - acc: 0.7765 - val_loss: 0.4792 - val_acc: 0.7655\n",
      "Epoch 4/10\n",
      "22451/22451 [==============================] - 175s 8ms/sample - loss: 0.4327 - acc: 0.7993 - val_loss: 0.4416 - val_acc: 0.7980\n",
      "Epoch 5/10\n",
      "22451/22451 [==============================] - 178s 8ms/sample - loss: 0.4098 - acc: 0.8111 - val_loss: 0.4361 - val_acc: 0.7972\n",
      "Epoch 6/10\n",
      "22451/22451 [==============================] - 189s 8ms/sample - loss: 0.3739 - acc: 0.8298 - val_loss: 0.4305 - val_acc: 0.7980\n",
      "Epoch 7/10\n",
      "22451/22451 [==============================] - 193s 9ms/sample - loss: 0.3428 - acc: 0.8468 - val_loss: 0.4259 - val_acc: 0.8072\n",
      "Epoch 8/10\n",
      "22451/22451 [==============================] - 186s 8ms/sample - loss: 0.3080 - acc: 0.8635 - val_loss: 0.4522 - val_acc: 0.7992\n",
      "Epoch 9/10\n",
      "22451/22451 [==============================] - 209s 9ms/sample - loss: 0.2737 - acc: 0.8840 - val_loss: 0.4687 - val_acc: 0.7904\n",
      "Epoch 10/10\n",
      "22451/22451 [==============================] - 209s 9ms/sample - loss: 0.2364 - acc: 0.9017 - val_loss: 0.4936 - val_acc: 0.7980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xa76ccf1bc8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Model\n",
    "\n",
    "model = Sequential() # Simple Sequential model\n",
    "\n",
    "# 1st Layer\n",
    "model.add(Conv2D(64, (3, 3), input_shape = X.shape[1:])) # X.shape gives (24946, 50, 50, 1)\n",
    "# 64 is the number of filters Integer, the dimensionality of the output space (i.e. the number of output filters in the \n",
    "# convolution), (3, 3) is the window /kernel size, input_shape will be (50, 50, 1) dynamically \n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2nd Layer\n",
    "model.add(Conv2D(64, (3, 3))) # X.shape gives (24946, 50, 50, 1)\n",
    "# 64 is the number of filters Integer, the dimensionality of the output space (i.e. the number of output filters in the \n",
    "# convolution), (3, 3) is the window /kernel size, input_shape will be (50, 50, 1) dynamically \n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2x64 Layer conv neural network\n",
    "\n",
    "#3rd layer\n",
    "model.add(Flatten()) # Convolution in 2D while dense layer needs a 1D dataset\n",
    "model.add(Dense(64)) # Final dense layer 64 nodes, probably not needed for this data\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1)) # Output layer\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", # categorical can also be used\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.1, callbacks=[tensorboard]) \n",
    "# batch_size implies how many samples at a time we want to pass\n",
    "# Fraction of the training data to be used as validation data. \n",
    "# The model will set apart this fraction of the training data, will not train on it, and will \n",
    "# evaluate the loss and any model metrics on this data at the end of each epoch.Here, its 10% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45dfeeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-32-nodes-0-dense-1621805167\n",
      "2-conv-32-nodes-0-dense-1621805167\n",
      "3-conv-32-nodes-0-dense-1621805167\n",
      "1-conv-64-nodes-0-dense-1621805167\n",
      "2-conv-64-nodes-0-dense-1621805167\n",
      "3-conv-64-nodes-0-dense-1621805167\n",
      "1-conv-128-nodes-0-dense-1621805167\n",
      "2-conv-128-nodes-0-dense-1621805167\n",
      "3-conv-128-nodes-0-dense-1621805167\n",
      "1-conv-32-nodes-1-dense-1621805167\n",
      "2-conv-32-nodes-1-dense-1621805167\n",
      "3-conv-32-nodes-1-dense-1621805167\n",
      "1-conv-64-nodes-1-dense-1621805167\n",
      "2-conv-64-nodes-1-dense-1621805167\n",
      "3-conv-64-nodes-1-dense-1621805167\n",
      "1-conv-128-nodes-1-dense-1621805167\n",
      "2-conv-128-nodes-1-dense-1621805167\n",
      "3-conv-128-nodes-1-dense-1621805167\n",
      "1-conv-32-nodes-2-dense-1621805167\n",
      "2-conv-32-nodes-2-dense-1621805167\n",
      "3-conv-32-nodes-2-dense-1621805167\n",
      "1-conv-64-nodes-2-dense-1621805167\n",
      "2-conv-64-nodes-2-dense-1621805167\n",
      "3-conv-64-nodes-2-dense-1621805167\n",
      "1-conv-128-nodes-2-dense-1621805167\n",
      "2-conv-128-nodes-2-dense-1621805167\n",
      "3-conv-128-nodes-2-dense-1621805167\n"
     ]
    }
   ],
   "source": [
    "# Part of Code for optimizing accuracy for models with different numbers of dense layers, layer sizes, \n",
    "# Output will be the various parameters we will train the model with (Name and model combinations)\n",
    "\n",
    "import time\n",
    "\n",
    "dense_layers = [0, 1, 2] # No of dense layers in the model\n",
    "layer_sizes = [32, 64, 128] # No of nodes in layer\n",
    "conv_layers = [1, 2, 3] # No of convoluted layers\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME) # Prints the specs of various parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37f4471f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-64-nodes-0-dense-1621806418\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "   32/17462 [..............................] - ETA: 10:36 - loss: 0.6931 - acc: 0.4688WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.379406). Check your callbacks.\n",
      "   64/17462 [..............................] - ETA: 8:31 - loss: 0.6923 - acc: 0.4844 WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.331720). Check your callbacks.\n",
      "17462/17462 [==============================] - 160s 9ms/sample - loss: 0.6603 - acc: 0.5935 - val_loss: 0.6122 - val_acc: 0.6696\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 179s 10ms/sample - loss: 0.5604 - acc: 0.7101 - val_loss: 0.5396 - val_acc: 0.7309\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 152s 9ms/sample - loss: 0.4862 - acc: 0.7705 - val_loss: 0.4884 - val_acc: 0.7643\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 168s 10ms/sample - loss: 0.4454 - acc: 0.7921 - val_loss: 0.4502 - val_acc: 0.7926\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 191s 11ms/sample - loss: 0.4141 - acc: 0.8135 - val_loss: 0.4457 - val_acc: 0.7938\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 218s 12ms/sample - loss: 0.3835 - acc: 0.8279 - val_loss: 0.4572 - val_acc: 0.7902\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 200s 11ms/sample - loss: 0.3545 - acc: 0.8403 - val_loss: 0.4387 - val_acc: 0.7950\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 183s 10ms/sample - loss: 0.3339 - acc: 0.8549 - val_loss: 0.4446 - val_acc: 0.7977\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 158s 9ms/sample - loss: 0.3066 - acc: 0.8649 - val_loss: 0.4234 - val_acc: 0.8124\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 153s 9ms/sample - loss: 0.2882 - acc: 0.8768 - val_loss: 0.4303 - val_acc: 0.8067\n"
     ]
    }
   ],
   "source": [
    "# Optimized model\n",
    "# Need to run only this cell for getting output for the optimized model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D \n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "# Sequential model\n",
    "# Dense layer\n",
    "# Flatten is used before feeding to the final Dense\n",
    "# Importing TensorBoard\n",
    "\n",
    "NAME = \"Cats-vs-dogs-cnn-64x3-{}\".format(int(time.time())) # Naming the model to identify in TensorBoard\n",
    "# Adding the timestamp\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs\\{}\".format(NAME))\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\", \"rb\")) # Loading the data saved\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "X = X/255.0 # Normalize the data to scale of 0 to 1 max value=255\n",
    "\n",
    "dense_layers = [0] # No of dense layers in the model eg. [0, 1, 2]\n",
    "layer_sizes = [64] # No of nodes in layer eg. [32, 64, 128]\n",
    "conv_layers = [3] # No of convoluted layers eg. [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME) # Prints the specs of parameters\n",
    "\n",
    "            model = Sequential() # Simple Sequential model\n",
    "\n",
    "            # 1st Layer\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape = X.shape[1:])) # X.shape gives (24946, 50, 50, 1)\n",
    "            # 64 is the number of filters Integer, the dimensionality of the output space (i.e. the number of output \n",
    "            # filters in the convolution), (3, 3) is the window /kernel size, input_shape will be (50, 50, 1) dynamically \n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            \n",
    "            for l in range(conv_layer-1): # We have already got 1 conv_layer above\n",
    "                # 2nd Layer\n",
    "                model.add(Conv2D(layer_size, (3, 3))) # X.shape gives (24946, 50, 50, 1)\n",
    "                # 64 is the number of filters Integer, the dimensionality of the output space (i.e. the number of output \n",
    "                # filters in the convolution), (3, 3) is the window /kernel size, input_shape will be (50, 50, 1) dynamically \n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "               \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            for l in range(dense_layer):\n",
    "                # Convolution is in 2D while dense layer needs a 1D dataset\n",
    "                model.add(Dense(layer_size)) # Final dense layer variable nodes here\n",
    "                model.add(Activation(\"relu\"))\n",
    "\n",
    "            model.add(Dense(1)) # Output layer\n",
    "            model.add(Activation(\"sigmoid\"))\n",
    "            # Sigmoid can be used here as this is a binary outcome situation - cat or dog\n",
    "\n",
    "            model.compile(loss=\"binary_crossentropy\", # categorical can also be used\n",
    "                         optimizer=\"adam\",\n",
    "                         metrics=[\"accuracy\"])\n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard]) \n",
    "            # batch_size implies how many samples at a time we want to pass\n",
    "            # Fraction of the training data to be used as validation data. \n",
    "            # The model will set apart this fraction of the training data, will not train on it, and will \n",
    "            # evaluate the loss and any model metrics on this data at the end of each epoch.\n",
    "            # Changed to 30% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35bf93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"64x3-CNN.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f866656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial article link: https://pythonprogramming.net/convolutional-neural-network-deep-learning-python-tensorflow-keras/\n",
    "# Video Link: https://www.youtube.com/watch?v=WvoLTXIjBYU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
